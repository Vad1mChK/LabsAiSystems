{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Лабораторная работа № 5 по дисциплине \"Системы искусственного интеллекта\"",
   "id": "91a280aa7b44a230"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Задание лабораторной работы\n",
    "\n",
    "0. Использовать [датасет с данными про оценки студентов инженерного и педагогического факультетов](https://archive.ics.uci.edu/dataset/856/higher+education+students+performance+evaluation) (для данного датасета нужно ввести метрику: студент успешный/неуспешный на основании грейда)\n",
    "1. Отобрать **случайным** образом sqrt(n) признаков\n",
    "2. Реализовать без использования сторонних библиотек построение дерева решений  (дерево не бинарное, numpy и pandas использовать можно, использовать список списков  для реализации  дерева - нельзя) для решения задачи бинарной классификации \n",
    "3. Провести оценку реализованного алгоритма с использованием Accuracy, precision и recall\n",
    "4. Построить кривые AUC-ROC и AUC-PR (в пунктах 3 и 4 использовать библиотеки нельзя)\n",
    "  - а можно хотя бы `matplotlib`? :blush:"
   ],
   "id": "6f7e5df980786d96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Выполнение лабораторной работы\n",
    "### 0. Установка и импорт библиотек, загрузка датасета\n",
    "\n",
    "Сначала установим библиотеки, если они уже не установлены."
   ],
   "id": "72117c4a318fa1d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install numpy pandas matplotlib",
   "id": "518dbd3df978fbbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Импортируем необходимые библиотеки.",
   "id": "74f162d64cf384d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "20f454b8a5b76289",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Клонируем датасет.",
   "id": "4c384e1720ef38aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('../datasets/DATA (1).csv')\n",
    "print(type(data))\n",
    "print(data)\n",
    "print(data.describe())\n",
    "data.head()"
   ],
   "id": "afd3240c4a1889b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 0.1. Фильтрация значений",
   "id": "a11a45b48948c126"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = data.dropna()\n",
    "data.describe()"
   ],
   "id": "474c9c5c5cb3e605",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Добавляем дополнительный признак: `SUCCESSFUL`. Документация датасета гласит, что значения признака `GRADE` соответствуют оценкам \n",
    "```\n",
    "OUTPUT Grade (0: Fail, 1: DD, 2: DC, 3: CC, 4: CB, 5: BB, 6: BA, 7: AA)\n",
    "```\n",
    ", поэтому будем считать, что студент успешный, если его оценка не ниже порога `threshold = 3` (CC)."
   ],
   "id": "622b16ac1537afd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "threshold = 3\n",
    "data['SUCCESSFUL'] = (data['GRADE'] >= threshold).astype(int)\n",
    "data.describe()"
   ],
   "id": "7ca4ddafa64484f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Список признаков\n",
    "Получим список признаков:"
   ],
   "id": "2207a6dce3dd01bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feature_columns = data.drop(['STUDENT ID', 'GRADE', 'SUCCESSFUL'], axis=1).columns\n",
    "# Calculate sqrt(n) where n is the number of feature columns\n",
    "sqrt_n = int(np.sqrt(feature_columns.size))\n",
    "# Randomly select sqrt(n) features\n",
    "selected_features = np.random.choice(feature_columns, size=sqrt_n, replace=False)\n",
    "selected_features"
   ],
   "id": "a5c213f007f1b160",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Построение дерева решений\n",
    "\n",
    "Используем алгоритм ID3 для построения дерева принятия решений. В нём выбор признака происходит на основании нормализованного прироста информации ($\\text{Gain}$). Это один из простейших в реализации алгоритмов построения дерева решений.\n"
   ],
   "id": "2b8aec279425d17d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.1. Энтропия\n",
    "\n",
    "Введём понятие энтропии.\n",
    "- Пусть $S$ -- датасет с $n$ элементами, $S_i$ -- его подмножества, принадлежащие к $i$-му классу, $i = \\overline{1,k}$, $1 < k \\leq n$.\n",
    "- Подмножество $S_i$, где определённый атрибут принимает $i$-е значение, называется классом.\n",
    "- $p_i = \\cfrac{|S_i|}{|S|}$ -- вероятность принадлежности элемента датасета $C \\in S$ к классу $S_i$, $\\sum\\limits_{i=1}^{k} p_i=1$.\n",
    "- **Энтропия** (информационная двоичная энтропия) -- это число бит информации, которое привносит нам  знание, что элемент $C$ принадлежит к одному из классов. Вычисляется по формуле: \n",
    "$$\n",
    "H(S) = -\\sum_{i=1}^{k} p_i \\cdot \\log_2(p_i).\n",
    "$$\n",
    "- Энтропия ограничена снизу и сверху: $0 \\leq H(S) \\leq \\log_2(k)$.\n",
    "- Энтропия принимает минимальное значение ($0$), если признак всегда принимает одинаковое значение ($k = 1$).\n",
    "- Энтропия принимает максимальное значение ($\\log_2 k$), когда число элементов в классах одинаково."
   ],
   "id": "341271caa6237b64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def entropy(y: pd.Series) -> float:\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / y.size\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "y = data['SUCCESSFUL']\n",
    "entropy(y)"
   ],
   "id": "46cbef22a5e13644",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.2. Прирост информации\n",
    "\n",
    "Введём понятие прироста информации / информационного выигрыша.\n",
    "- Пусть:\n",
    "    - $S$ -- текущий датасет.\n",
    "    - $A$ -- признак, который мы рассматриваем.\n",
    "    - $\\text{Values}(A)$ -- возможные значения признака $A$.\n",
    "    - $S_v$ -- подмножество $S$, где признак $A$ имеет значение $v$.\n",
    "    - $H(S)$ -- энтропия исходного набора данных $S$.\n",
    "    - $H(S_v)$ -- энтропия подмножества $S_v$.\n",
    "- **Прирост информации** измеряет, насколько использование признака $A$ для разбиения набора данных $S$ уменьшает неопределенность (энтропию) в отношении целевой переменной.\n",
    "- Вычисляется по формуле:\n",
    "$$\n",
    "\\text{Gain}(S, A) = H(S) - \\sum\\limits_{v\\in \\text{Values}(A)} \\frac{|S_v|}{|S|}H(S_v).\n",
    "$$\n",
    "- В этой формуле $\\sum\\limits_{v\\in \\text{Values}(A)} \\frac{|S_v|}{|S|}H(S_v)$ -- взвешенная сумма энтропий подмножеств после разбиения. Вес ($\\frac{|S_v|}{|S|}$) указывает вероятность попадания в подмножество $S_v$ (т. е. долю $S_v$ в $S$)."
   ],
   "id": "47f4e2c0318878ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def information_gain(s: pd.DataFrame, y: pd.Series, a: str | int) -> float:\n",
    "    h_s = entropy(y) # Entropy of the entire dataset\n",
    "    values = s[a].unique() # All possible values of feature A\n",
    "    \n",
    "    weighted_entropy = 0.0\n",
    "    \n",
    "    for v in values:\n",
    "        # Select subset S_v where feature A equals v\n",
    "        indices = s[a] == v\n",
    "        s_v = s[indices]\n",
    "        y_v = y[indices]\n",
    "        \n",
    "        h_s_v = entropy(y_v) # Entropy of the subset\n",
    "        weighted_entropy += (s_v.shape[0] / s.shape[0]) * h_s_v\n",
    "    \n",
    "    gain = h_s - weighted_entropy\n",
    "    return gain"
   ],
   "id": "9eaabf812fc6f5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.3. Построение дерева решений\n",
    "Сначала создадим класс узла дерева решений:"
   ],
   "id": "8dd8dcc2f1b4e5ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class DecisionTreeNode:\n",
    "    is_leaf: bool\n",
    "    prediction: int | None = None\n",
    "    probability: float = None  # Probability of the positive class\n",
    "    feature: str | None = None\n",
    "    children: dict = field(default_factory=dict)\n",
    "    majority_class: int | None = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.is_leaf:\n",
    "            return f\"Leaf(pred={self.prediction}, prob={self.probability:.2f})\"\n",
    "        else:\n",
    "            return f\"Node(feature={self.feature}, majority={self.majority_class})\"\n",
    "\n",
    "\n"
   ],
   "id": "731b1b9d2158fb44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Рекурсивное построение дерева решений:\n",
    "1. Если значение целевой переменной во всех записях одинаково, вернуть лист (узел, не имеющий потомков).\n",
    "2. Если признаков не осталось или достигнута максимальная глубина, также вернуть лист.\n",
    "3. Выбрать лучший признак для разделения, для которого будет наибольшим прирост информации.\n",
    "4. Создать новый узел с лучшим признаком.\n",
    "5. Разделить датасет на основе лучшего признака. Добавить текущему узлу потомков, которые строятся по тем же принципам, что и родительский узел, но используют подмножество датасета и списка признаков."
   ],
   "id": "806b4f5270ff693c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def build_tree(s: pd.DataFrame, y: pd.Series, features: list[str], depth: int = 0,\n",
    "               max_depth: int = None, min_samples_split=2, min_samples_leaf=1,\n",
    "               min_information_gain=1e-5) -> DecisionTreeNode:\n",
    "    # Base case: stopping conditions (pre-pruning)\n",
    "    if y.nunique() == 1 or len(features) == 0 or \\\n",
    "       (max_depth is not None and depth >= max_depth) or len(y) < min_samples_split:\n",
    "        prediction = y.mode()[0]\n",
    "        probability = y.mean()  # Proportion of positive samples\n",
    "        return DecisionTreeNode(is_leaf=True, prediction=prediction, probability=probability)\n",
    "    \n",
    "    # Compute majority class for current node\n",
    "    majority_class = y.mode()[0]\n",
    "    \n",
    "    # Compute information gain for all features\n",
    "    gains = [information_gain(s, y, feature) for feature in features]\n",
    "    best_gain = max(gains)\n",
    "    if best_gain < min_information_gain:\n",
    "        prediction = y.mode()[0]\n",
    "        probability = y.mean()\n",
    "        return DecisionTreeNode(is_leaf=True, prediction=prediction, probability=probability)\n",
    "    \n",
    "    best_feature_index = gains.index(best_gain)\n",
    "    best_feature = features[best_feature_index]\n",
    "    \n",
    "    # Create the node for the best feature\n",
    "    node = DecisionTreeNode(is_leaf=False, feature=best_feature, majority_class=majority_class)\n",
    "    \n",
    "    # Remove the best feature from the feature list for the next level\n",
    "    remaining_features = [f for f in features if f != best_feature]\n",
    "    \n",
    "    # Split the dataset by the best feature and build subtrees recursively\n",
    "    for value in s[best_feature].unique():\n",
    "        indices = s[best_feature] == value\n",
    "        s_v = s[indices]\n",
    "        y_v = y[indices]\n",
    "        \n",
    "        if len(y_v) == 0:\n",
    "            prediction = y.mode()[0]  # Fallback to the majority class\n",
    "            probability = y.mean()  # Fallback to the overall probability\n",
    "        else:\n",
    "            prediction = y_v.mode()[0]\n",
    "            probability = y_v.mean()\n",
    "        node.children[value] = DecisionTreeNode(is_leaf=True, prediction=prediction, probability=probability)\n",
    "\n",
    "    return node\n",
    "\n"
   ],
   "id": "41338c35afb31240",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Реализуем функцию предсказания (использующую существующее дерево):\n",
    "1. Если данный узел -- лист, возвращаем его предсказание.\n",
    "2. Если в узле встретилось неизвестное значение (не встреченное в тренировочном датасете), возвращаем моду целевой переменной.\n",
    "3. Иначе вычисляем предсказание для потомка, у которого данный признак имеет то же значение, что и у признака текущего узла."
   ],
   "id": "9d69b383ada92c6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_single(tree: DecisionTreeNode, sample: pd.Series) -> int:\n",
    "    \"\"\"\n",
    "    Predict the class label for a single sample using the decision tree.\n",
    "    \n",
    "    :param tree: The root node of the decision tree.\n",
    "    :param sample: A single sample (features).\n",
    "    :return: The predicted label.\n",
    "    \"\"\"\n",
    "    if tree.is_leaf:\n",
    "        return tree.prediction\n",
    "    value = sample.get(tree.feature)\n",
    "    if value in tree.children:\n",
    "        return predict_single(tree.children[value], sample)\n",
    "    else:\n",
    "        return tree.majority_class\n",
    "\n",
    "def predict(tree: DecisionTreeNode, s: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Predict the class labels for a dataset using the decision tree.\n",
    "    \n",
    "    :param tree: The root node of the decision tree.\n",
    "    :param s: The dataset (features).\n",
    "    :return: The predicted labels (numpy array).\n",
    "    \"\"\"\n",
    "    return np.array([predict_single(tree, row) for _, row in s.iterrows()])\n"
   ],
   "id": "13c84d89b2f723fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.4. Разделение датасета на обучающую и тестовую выборку\n",
   "id": "8a8bdacfc858ef6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = data[selected_features]\n",
    "y = data['SUCCESSFUL']\n",
    "selected_features"
   ],
   "id": "969062dd51e6389a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TRAIN_PERCENTAGE = 0.7\n",
    "assert 0 < TRAIN_PERCENTAGE < 1"
   ],
   "id": "a0be396e8e18086e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_size = int(data.shape[0] * TRAIN_PERCENTAGE)\n",
    "\n",
    "x_train = x[:train_size]\n",
    "x_test = x[train_size:]\n",
    "y_train = y[:train_size]\n",
    "y_test = y[train_size:]"
   ],
   "id": "c2b54c204d1513a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.5. Обучение модели\n",
    "\n",
    "Обучим модель на тренировочном датасете:"
   ],
   "id": "e81598f7ffef3936"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "decision_tree = build_tree(x_train, y_train, selected_features)\n",
    "decision_tree"
   ],
   "id": "5cca08485c263f7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.6. Использование модели\n",
    "\n",
    "Используем модель для предсказания целевой переменной для тестового набора. (Также проверим её на тренировочном наборе, чтобы убедиться, что не было переобучения)"
   ],
   "id": "8e253644a8e5731a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred_train = predict(decision_tree, x_train)\n",
    "y_pred_test = predict(decision_tree, x_test)\n",
    "y_pred_test"
   ],
   "id": "d89f10222708a0cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Оценка параметров модели\n",
    "\n",
    "Введём обозначения:\n",
    "\n",
    "|                       | predicted positive  | predicted negative  |\n",
    "|-----------------------|---------------------|---------------------|\n",
    "| **actually positive** | TP (True Positive)  | FN (False Negative) |\n",
    "| **actually negative** | FP (False Negative) | TN (True Negative)  |\n",
    "\n",
    "Матрица\n",
    "\n",
    "$$\n",
    "\\left(\\begin{matrix}\n",
    "    TP & FN \\\\\n",
    "    FP & TN\n",
    "\\end{matrix}\\right)\n",
    "$$\n",
    "\n",
    "также известна как матрица ошибок. В её ячейках находятся количества правильно и неправильно предсказанных элементов:\n",
    "- $TP$ -- предсказан позитивный класс, на самом деле позитивный\n",
    "- $FN$ -- предсказан негативный класс, на самом деле позитивный\n",
    "- $FP$ -- предсказан позитивный класс, на самом деле негативный\n",
    "- $TN$ -- предсказан негативный класс, на самом деле негативный\n",
    "\n",
    "Расчёт метрик:\n",
    "$$\n",
    "\\text{Accuracy} = \\cfrac{TP+TN}{TP+FN+FP+TN}.\n",
    "$$\n",
    "$$\n",
    "\\text{Precision} = \\cfrac{TP}{TP+FP}.\n",
    "$$\n",
    "$$\n",
    "\\text{Recall} = \\cfrac{TP}{TP+FN}.\n",
    "$$\n",
    "$$\n",
    "F_1 = \\cfrac{2 \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}.\n",
    "$$"
   ],
   "id": "9d6b96fb71f6e199"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class ConfusionMatrix:\n",
    "    tp: int = 0  # True Positives\n",
    "    tn: int = 0  # True Negatives\n",
    "    fp: int = 0  # False Positives\n",
    "    fn: int = 0  # False Negatives\n",
    "\n",
    "    @classmethod\n",
    "    def from_predictions(cls, y_true: np.ndarray, y_pred: np.ndarray) -> 'ConfusionMatrix':\n",
    "        assert y_true.shape == y_pred.shape, \"Shapes of y_true and y_pred must match\"\n",
    "        \n",
    "        tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "        tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "        fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "        fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "        \n",
    "        return cls(tp=tp, tn=tn, fp=fp, fn=fn)\n",
    "\n",
    "    def accuracy(self) -> float:\n",
    "        return (self.tp + self.tn) / (self.tp + self.tn + self.fp + self.fn)\n",
    "\n",
    "    def precision(self) -> float:\n",
    "        return self.tp / (self.tp + self.fp) if (self.tp + self.fp) > 0 else 0.0\n",
    "\n",
    "    def recall(self) -> float:\n",
    "        return self.tp / (self.tp + self.fn) if (self.tp + self.fn) > 0 else 0.0\n",
    "\n",
    "    def f1_score(self) -> float:\n",
    "        p = self.precision()\n",
    "        r = self.recall()\n",
    "        return 2 * p * r / (p + r) if (p + r) > 0 else 0.0\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"ConfusionMatrix(tp={self.tp}, tn={self.tn}, fp={self.fp}, fn={self.fn})\"\n"
   ],
   "id": "b36dfed6319b31cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cm_train = ConfusionMatrix.from_predictions(y_true=y_train, y_pred=y_pred_train)\n",
    "print(f'Training dataset confusion matrix: {cm_train}')\n",
    "print(f'Accuracy: {cm_train.accuracy():.6f}')\n",
    "print(f'Precision: {cm_train.precision():.6f}')\n",
    "print(f'Recall: {cm_train.recall():.6f}')\n",
    "print(f'F1 score: {cm_train.f1_score():.6f}')"
   ],
   "id": "285b9c9701e2bd1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cm_test = ConfusionMatrix.from_predictions(y_true=y_test, y_pred=y_pred_test)\n",
    "print(f'Test dataset confusion matrix: {cm_test}')\n",
    "print(f'Accuracy: {cm_test.accuracy():.6f}')\n",
    "print(f'Precision: {cm_test.precision():.6f}')\n",
    "print(f'Recall: {cm_test.recall():.6f}')\n",
    "print(f'F1 score: {cm_test.f1_score():.6f}')"
   ],
   "id": "defdefd2894730a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Видим, что точность очень низка (даже хуже, чем если бы мы выдавали одно и то же предсказание при любых входных данных). Возможно, это связано с переобучением, т. к. $F_1$ для тренировочной выборки значительно выше, чем для тестовой.\n",
    "\n",
    "Можно улучшать точность модели несколькими способами:\n",
    "- Ограничение глубины дерева.\n",
    "- Отсечение малозначимых ветвей (частично реализовано выше).\n",
    "- Кросс-валидация и другие техники для лучшего обобщения.\n",
    "\n",
    "Попробуем варьировать максимальную глубину дерева:"
   ],
   "id": "bdc3667c7219375"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "depths = range(1, 16 + 1)\n",
    "\n",
    "results: dict[int, ConfusionMatrix] = {}\n",
    "\n",
    "for depth in depths:\n",
    "    decision_tree = build_tree(x_train, y_train, selected_features, max_depth=depth)\n",
    "    y_pred_train = predict(decision_tree, x_train)\n",
    "    y_pred_test = predict(decision_tree, x_test)\n",
    "    cm_train = ConfusionMatrix.from_predictions(y_true=y_train, y_pred=y_pred_train)\n",
    "    cm_test = ConfusionMatrix.from_predictions(y_true=y_test, y_pred=y_pred_test)\n",
    "    results[depth] = cm_test\n",
    "    print(f\"max_depth: {depth}, train f1 = {cm_train.f1_score():.6f}, test f1 = {cm_test.f1_score():.6f}\")"
   ],
   "id": "7f02fb0011c63250",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "optimal_max_depth = max(results, key=lambda k: results[k].f1_score())\n",
    "optimal_confusion_matrix = results[optimal_max_depth]\n",
    "print(f'optimal f1={optimal_confusion_matrix.f1_score():.6f} achieved at max_depth={optimal_max_depth}')"
   ],
   "id": "aa0f9583879a42af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Можно заметить, что между разными запусками блокнота максимальное значение тестового $F_1$ может сильно варьироваться. Это связано с тем, что датасет маленький, и разбиение на обучающую и тестовую выборку здесь играет существенную роль.",
   "id": "15c5a580c30a52a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Построение кривых AUC-ROC, AUC-PR\n",
    "Построим кривые AUC-ROC и AUC-PR для нашего дерева решений.\n",
    "\n",
    "AUC-ROC (Area Under the Receiver Operating Characteristic Curve) -- это показатель, который оценивает качество бинарной классификации путем измерения точности TPR и FPR. Чем больше AUC-ROC, тем лучше модель предсказывает вероятности классов.\n",
    "\n",
    "AUC-PR (Area Under the Precision-Recall Curve) -- это показатель, который оценивает качество бинарной классификации путем измерения точности и полноты.\n",
    "\n",
    "Сначала напишем функции, которые предсказывают вероятность того или иного исхода.\n"
   ],
   "id": "6ea389179a9c5bdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_single_probability(tree: DecisionTreeNode, sample: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Predict the probability for a single sample using the decision tree.\n",
    "\n",
    "    :param tree: The root node of the decision tree.\n",
    "    :param sample: A single sample (features).\n",
    "    :return: The predicted probability.\n",
    "    \"\"\"\n",
    "    if tree.is_leaf:\n",
    "        return tree.probability\n",
    "    value = sample.get(tree.feature)\n",
    "    if value in tree.children:\n",
    "        return predict_single_probability(tree.children[value], sample)\n",
    "    else:\n",
    "        # If unseen value, return the probability of the current node\n",
    "        return tree.probability\n",
    "    \n",
    "def predict_probabilities(tree: DecisionTreeNode, s: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Predict probabilities for a dataset using the decision tree.\n",
    "\n",
    "    :param tree: The root node of the decision tree.\n",
    "    :param s: The dataset (features).\n",
    "    :return: The predicted probabilities (numpy array).\n",
    "    \"\"\"\n",
    "    return np.array([predict_single_probability(tree, row) for _, row in s.iterrows()])\n",
    "\n",
    "def calculate_auc(x: list, y: list) -> float:\n",
    "    auc = 0.0\n",
    "    for i in range(1, len(x)):\n",
    "        auc += (x[i] - x[i - 1]) * (y[i] + y[i - 1]) / 2\n",
    "    return auc\n"
   ],
   "id": "a50f7a6a59a2b012",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "При разных порогах вероятности (всё, что не ниже порога, считается истиной) высчитываем метрики, необходимые для построения кривых:",
   "id": "a9433b1fed697a6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Build the tree with the modified function\n",
    "tree = build_tree(x_train, y_train, selected_features)\n",
    "\n",
    "# Predict probabilities on the test dataset\n",
    "y_scores = predict_probabilities(tree, x_test)  # Predicted probabilities\n",
    "y_true = y_test.values  # True labels\n",
    "\n",
    "# Define thresholds to calculate TPR, FPR, Precision, and Recall at different thresholds\n",
    "thresholds = np.linspace(0, 1, num=100)\n",
    "\n",
    "# Initialize lists to store TPR, FPR, Precision, and Recall\n",
    "tpr_list = []\n",
    "fpr_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_scores >= threshold).astype(int)  # Convert probabilities to binary predictions based on the threshold\n",
    "    \n",
    "    # Create a confusion matrix for this threshold\n",
    "    cm = ConfusionMatrix.from_predictions(y_true, y_pred)\n",
    "    \n",
    "    # Calculate True Positive Rate (Recall) and False Positive Rate\n",
    "    tpr = cm.recall()  # TPR is the same as recall\n",
    "    fpr = cm.fp / (cm.fp + cm.tn) if (cm.fp + cm.tn) > 0 else 0.0\n",
    "    \n",
    "    # Calculate Precision and Recall\n",
    "    precision = cm.precision()\n",
    "    recall = cm.recall()\n",
    "    \n",
    "    # Append results to the lists\n",
    "    tpr_list.append(tpr)\n",
    "    fpr_list.append(fpr)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)"
   ],
   "id": "a3659fb8ab060e30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Строим кривые (простите за `matplotlib`):",
   "id": "1026e41fe7e34432"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_list, tpr_list, label='ROC Curve')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # Diagonal line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the Precision-Recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_list, precision_list, label='Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "a0f493038727b122",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Вычислим площадь под кривой ROC и PR:",
   "id": "ad733e6d5c938c74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate and print AUC-ROC\n",
    "auc_roc = abs(calculate_auc(fpr_list, tpr_list))\n",
    "print(f\"AUC-ROC: {auc_roc:.6f}\")\n",
    "# Calculate and print AUC-PR\n",
    "auc_pr = abs(calculate_auc(recall_list, precision_list))\n",
    "print(f\"AUC-PR: {auc_pr:.6f}\")\n"
   ],
   "id": "6d63ba6f01fa14e1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
