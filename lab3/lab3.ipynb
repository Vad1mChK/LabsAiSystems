{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Лабораторная работа № 3 по дисциплине \"Системы искусственного интеллекта\"",
   "id": "6a15e0f206259d0c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Задание лабораторной работы\n",
    "0. Датасет:\n",
    "    - Датасет [про обучение студентов](https://www.kaggle.com/datasets/nikhil7280/student-performance-multiple-linear-regression)\n",
    "1. Получите и визуализируйте (графически) статистику по датасету (включая количество, среднее значение, стандартное отклонение, минимум, максимум и различные квантили).\n",
    "2. Проведите предварительную обработку данных, включая обработку отсутствующих значений, кодирование категориальных признаков и нормировка.\n",
    "3. Разделите данные на обучающий и тестовый наборы данных.\n",
    "4. Реализуйте линейную регрессию с использованием метода наименьших квадратов без использования сторонних библиотек, кроме NumPy и Pandas (для использования коэффициентов использовать библиотеки тоже нельзя). Использовать минимизацию суммы квадратов разностей между фактическими и предсказанными значениями для нахождения оптимальных коэффициентов.\n",
    "5. Постройте **три модели** с различными наборами признаков. Для каждой модели проведите оценку производительности, используя метрику коэффициент детерминации, чтобы измерить, насколько хорошо модель соответствует данным.\n",
    "6. Сравните результаты трех моделей и сделайте выводы о том, какие признаки работают лучше всего для каждой модели.\n",
    "7. Бонусное задание\n",
    "    - Ввести синтетический признак при построении модели"
   ],
   "id": "7db7d5d05cbd88a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Выполнение лабораторной работы\n",
    "### 0. Установка и импорт библиотек, загрузка датасета\n",
    "\n",
    "Сначала установим библиотеки, если они уже не установлены."
   ],
   "id": "2a52c7384b31da1b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import math\n",
    "!pip install numpy pandas matplotlib seaborn"
   ],
   "id": "7d5c056d7aef98db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Импортируем необходимые библиотеки.",
   "id": "e7db56a2437c5b7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "4b578944756358e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Загрузим датасет и выведем основную статистику по нему и 5 первых строк:",
   "id": "31ac93d92c87983e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('Student_Performance.csv')\n",
    "print(data.describe())\n",
    "data.head()"
   ],
   "id": "c3f06f76e4e99e00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Визуализация статистики\n",
    "\n",
    "Визуализируем эту статистику:"
   ],
   "id": "8e3cd44e080ae41c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Правило Стёрджиса для выбора оптимального количества интервалов в гистограмме \n",
    "def sturges(n):\n",
    "    return int(1 + np.floor(np.log2(n)))\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "desc = data.describe()\n",
    "\n",
    "non_numeric_column_count = 0\n",
    "\n",
    "for i, col in enumerate(desc.columns):\n",
    "    if data[col].dtype == 'object':\n",
    "        non_numeric_column_count += 1\n",
    "        continue\n",
    "    \n",
    "    ax = fig.add_subplot(2, 3, i + 1 - non_numeric_column_count)\n",
    "    \n",
    "    bin_count = min(sturges(len(data[col])), len(data[col].unique()))\n",
    "    \n",
    "    hist = ax.hist(data[col], bins=bin_count)\n",
    "    \n",
    "    count = int(desc[col]['count'])\n",
    "    mean = desc[col]['mean']\n",
    "    std = desc[col]['std']\n",
    "    min_val = desc[col]['min']\n",
    "    max_val = desc[col]['max']\n",
    "    q25 = desc[col]['25%']\n",
    "    median = desc[col]['50%']\n",
    "    q75 = desc[col]['75%']\n",
    "    \n",
    "    line_mean = ax.plot([mean, mean], [0, np.max(hist[0])], color='green', label='Mean')\n",
    "    line_mean_minus_std = ax.plot([mean - std, mean - std], [0, np.max(hist[0])],\n",
    "                                  color='green', linestyle='dashed', label='Mean -/+ StD ')\n",
    "    line_mean_plus_std = ax.plot([mean + std, mean + std], [0, np.max(hist[0])],\n",
    "                                 color='green', linestyle='dashed')\n",
    "    line_median = ax.plot([median, median], [0, np.max(hist[0])], \n",
    "                          color='yellow', label='50% Quantile')\n",
    "    line_q25 = ax.plot([q25, q25], [0, np.max(hist[0])],\n",
    "                       color='yellow', linestyle='dashed', label='25% / 75% Quantile')\n",
    "    line_q75 = ax.plot([q75, q75], [0, np.max(hist[0])],\n",
    "                       color='yellow', linestyle='dashed') \n",
    "    line_min = ax.plot([min_val, min_val], [0, np.max(hist[0])], color='red', label='Min / Max')\n",
    "    line_max = ax.plot([max_val, max_val], [0, np.max(hist[0])], color='red')\n",
    "    \n",
    "    ax.set_title(\n",
    "f\"\"\"\n",
    "{col}\n",
    "count = {count}; min = {min_val:.6}; max = {max_val:.6};\n",
    "mean = {mean:.6}; std = {std:.6};\n",
    "q25 = {q25:.6}; median = {median:.6}; q75 = {q75:.6};\n",
    "\"\"\"\n",
    "    )\n",
    "    ax.legend()\n",
    "    ax.plot()\n",
    "    \n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "id": "aa36f76bc26e747d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Предварительная обработка данных\n",
    "Обработка отсутствующих значений:"
   ],
   "id": "8c29fc1120091eaa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data = data.dropna(axis='rows')  # Drop rows with missing values",
   "id": "a7e68276b74500fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Кодирование категориальных признаков:\n",
    "- Категориальным является только признак `Extracurricular Activities` (принимает значения `Yes`, `No`). Все остальные -- числовые.\n",
    "\n",
    "Будем кодировать этот признак числом (`'No' : 0, 'Yes' : 1`)."
   ],
   "id": "b7e4e7c3d8cec556"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data['Extracurricular Activities'] = data['Extracurricular Activities'].map({'No': 0, 'Yes': 1})\n",
    "data"
   ],
   "id": "bd463caaa1e5e035",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "44fd31b67077c784"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Нормализуем данные.\n",
    "Нормализацию осуществляем по принципу:\n",
    "$$\n",
    "x_i' = \\cfrac{x_i - \\bar{X}}{\\sigma},\n",
    "$$\n",
    "где $\\bar X$ -- выборочное среднее, $\\sigma$ -- стандартное отклонение."
   ],
   "id": "a52c5d01e49db6f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "norm_data = (data - data.mean()) / data.std()\n",
    "norm_data"
   ],
   "id": "9d09fd1de066d9d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "norm_data.describe()",
   "id": "d673f279a545fac9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Разбиение данных на обучающий и тестовый набор данных\n",
    "\n",
    "Разделим данные в соотношении 80:20 (80% -- обучающий набор данных, 20% -- тестовый набор данных)."
   ],
   "id": "e123fab503c1b6ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TRAIN_DATA_PERCENTAGE = 0.8\n",
    "assert 0 < TRAIN_DATA_PERCENTAGE < 1"
   ],
   "id": "b4ec7c9895ce7a4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "norm_data = norm_data.sample(frac=1).reset_index(drop=True)  # Shuffle data\n",
    "\n",
    "train_size = int(len(norm_data) * TRAIN_DATA_PERCENTAGE)\n",
    "\n",
    "train_data, test_data = norm_data[:train_size], norm_data[train_size:]"
   ],
   "id": "4d3c45de2663db8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Линейная регрессия с помощью МНК\n",
    "#### 4.0. Функции для построения линейной регрессии и оценки производительности\n",
    "\n",
    "Модель линейной регрессии предполагает, что зависимость между зависимой переменной $y$ и независимыми переменными $x_1$, $x_2$, ..., $x_k$ --- линейная. Иными словами,\n",
    "\n",
    "$$\n",
    "y = \\beta_1 + \\beta_2 x_1 + \\beta_3 x_2 + \\dots + \\beta_{k+1} x_k + \\varepsilon,\n",
    "$$\n",
    "\n",
    "где $\\beta_i$ -- параметры (коэффициенты) модели; $x_i$ -- регрессоры (факторы) модели; $\\varepsilon$ -- случайная ошибка модели.\n",
    "\n",
    "Для нахождения коэффициентов линейной регрессии зачастую используется метод наименьших квадратов (МНК). Его суть состоит в том, чтобы найти такой вектор коэффициентов $\\hat{\\beta_t}$, чтобы сумма квадратов отклонений (ошибок, или остатков регрессии) $e_t$ будет минимальной:\n",
    "$$\n",
    "\\hat{\\beta}=\\arg\\min\\limits_{\\beta} RSS(\\beta),\n",
    "$$\n",
    "где $RSS$ (сумма квадратов остатков) определяется как:\n",
    "$$\n",
    "RSS = e^T e = \\sum\\limits_{i=1}^{n} e_i^2 = \\sum\\limits_{i=1}^{n}(y_i - f(x_i, \\beta))^2,\n",
    "$$\n",
    "где $f(x_i, \\beta)$ -- функция (в данном случае -- линейная), аппроксимирующая $y_i$ и известная с точностью до некоторых неизвестных параметров $\\beta$.\n",
    "\n",
    "В матричной форме оценку этих коэффициентов можно выразить следующим образом:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = (X^T X)^{-1}X^T Y,\n",
    "$$\n",
    "где $Y$ -- вектор наблюдаемых значений зависимой переменной, $X$ -- матрица $n\\times k$ ($n$ -- число наблюдений; $k$ -- число независимых переменных; в каждом столбце стоят значения одной переменной по всем наблюдениям; каждая строка --- одно наблюдение).\n",
    "\n",
    "Чтобы получить модель с константой $\\hat{\\beta_0}$, задающей смещение по $y$ (intercept), нужно приписать к матрице $X$ слева столбец из единиц. В таком случае линия (или гиперплоскость) регрессии будет проходить не через начало координат, а через \"центр тяжести\" данных."
   ],
   "id": "27bdf4ab9e6ae712"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def linear_regression(x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    return np.linalg.inv(x.T @ x) @ x.T @ y"
   ],
   "id": "199ebd21f1e05baf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "В таком случае коэффициенты будут предсказываться следующим образом:\n",
    "$$\n",
    "\\hat{y} = \\hat{\\beta_0} + \\sum_{i=1}^{k}\\hat{\\beta}_{i+1}x_{i},\n",
    "$$\n",
    "или, в матричной форме:\n",
    "$$\n",
    "\\hat{y} = X\\hat{\\beta}.\n",
    "$$"
   ],
   "id": "764aee9d6e9498fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict(x: np.ndarray, beta: np.ndarray) -> np.ndarray:\n",
    "    return x @ beta"
   ],
   "id": "da7b71e9744e8434",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Важной характеристикой модели является коэффициент детерминации $R^2$, характеризующий, насколько дисперсия зависимой переменной \"объяснена\", т. е. доля дисперсии зависимой переменной, объясняемая независимыми переменными. Чем меньше дисперсия случайной ошибки, тем ближе коэффициент к 1.\n",
    "\n",
    "В случае линейной регрессии вычисляется по формуле:\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\cfrac{RSS}{TSS}.\n",
    "$$\n",
    "\n",
    "Здесь $RSS$ -- сумма квадратов остатков (Residual Sum of Squares):\n",
    "$$\n",
    "RSS = \\sum_{i=1}^n(Y_i-\\hat{Y}_i)^2 = (Y-X\\hat{\\beta})^T(Y-X\\hat{\\beta})\n",
    "$$\n",
    "\n",
    "Здесь $TSS$ -- общая сумма квадратов (Total Sum of Squares), вычисляемая по формуле:\n",
    "$$\n",
    "TSS = \\sum_{i=1}^n(Y_i-\\bar{Y})^2,\n",
    "$$\n",
    "\n",
    "где $\\bar{Y}$ -- выборочное среднее зависимой переменной."
   ],
   "id": "390a71f58d3f3de5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_r2(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    rss = np.sum(np.square(y_true - y_pred))\n",
    "    tss = np.sum(np.square(y_true - y_true.mean()))\n",
    "    r2 = 1 - rss / tss\n",
    "    return r2"
   ],
   "id": "7fe5e27012e8044",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Напишем функцию, которая строит линейную регрессию, а затем считает $R^2$ и на обучающем, и на тестовом наборе.",
   "id": "382946902d46538d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_coeffs_and_r2_score(train_data: pd.DataFrame,\n",
    "                       test_data: pd.DataFrame,\n",
    "                       dependent_variable: str,\n",
    "                       variables_to_exclude: list[str] = (),\n",
    "                       variables_to_keep: list[str] = ()) -> dict[str, object]:\n",
    "    assert not variables_to_keep or not variables_to_exclude, 'Cannot specify both variables to exclude and variables to keep'\n",
    "    \n",
    "    if variables_to_keep:\n",
    "        # If variables_to_keep is provided, only keep these features\n",
    "        x_train = train_data[list(variables_to_keep)]\n",
    "        x_test = test_data[list(variables_to_keep)]\n",
    "    else:\n",
    "        # Otherwise drop the excluded variables and the dependent variable\n",
    "        x_train = train_data.drop([dependent_variable] + list(variables_to_exclude), axis=1)\n",
    "        x_test = test_data.drop([dependent_variable] + list(variables_to_exclude), axis=1)\n",
    "    \n",
    "    # Add intercept (column of ones) to both train and test sets\n",
    "    x_train = np.column_stack((np.ones(shape=x_train.shape[0]), x_train.values))\n",
    "    x_test = np.column_stack((np.ones(shape=x_test.shape[0]), x_test.values))\n",
    "    y_train = train_data[dependent_variable]\n",
    "    y_test = test_data[dependent_variable]\n",
    "    \n",
    "    coeffs = linear_regression(x_train, y_train)\n",
    "    \n",
    "    y_pred_train = predict(x_train, coeffs)\n",
    "    r2_train = calculate_r2(y_train, y_pred_train)\n",
    "    \n",
    "    y_pred_test = predict(x_test, coeffs)\n",
    "    r2_test = calculate_r2(y_test, y_pred_test)\n",
    "    \n",
    "    return {\n",
    "        'coeffs': coeffs,\n",
    "        'r2_train': r2_train,\n",
    "        'r2_test': r2_test\n",
    "    }"
   ],
   "id": "1faa8e3b932db8ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 4.1. Полный набор признаков\n",
    "Будем оценивать зависимость индекса успеваемости (`Performance Index`) от всех прочих признаков."
   ],
   "id": "c8f8082a45ad845a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result1 = calculate_coeffs_and_r2_score(train_data, test_data, 'Performance Index')\n",
    "result1"
   ],
   "id": "a530d56fb75750f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 4.2. Неполный набор признаков\n",
    "Исключим из модели признаки \"часы сна\" (`Sleep Hours`) и \"внеучебная деятельность\" (`Extracurricular Activities`), ведь кому нужен этот ваш сон и смена деятельности? В остальном выполняем те же самые действия, что и в предыдущих примерах."
   ],
   "id": "4b373be264c20474"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result2 = calculate_coeffs_and_r2_score(\n",
    "    train_data, test_data, 'Performance Index',\n",
    "    variables_to_exclude=['Sleep Hours', 'Extracurricular Activities'],\n",
    ")\n",
    "result2"
   ],
   "id": "163e91ee6e2d7756",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 4.3. Неполный набор признаков (С твистом)\n",
    "Впрочем, я поменял своё мнение: \"часы сна\" (Sleep Hours) и \"внеучебная деятельность\" (Extracurricular Activities) действительно очень важны ~~(В дальнейшем мы поймём, что это сарказм)~~. Теперь оставим только эти признаки."
   ],
   "id": "c8a78deb20d38bb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result3 = calculate_coeffs_and_r2_score(\n",
    "    train_data, test_data, 'Performance Index',\n",
    "    variables_to_keep=['Sleep Hours', 'Extracurricular Activities'],\n",
    ")\n",
    "result3"
   ],
   "id": "df3055b0a3af8748",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 4.4. Все наборы признаков\n",
    "Ха. Хаха. Хахаха.\n",
    "Вам меня не остановить."
   ],
   "id": "ee6a71315aef9ed5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from itertools import combinations\n",
    "from math import comb\n",
    "\n",
    "desc = norm_data.describe()\n",
    "desc_without_dependent = desc.drop('Performance Index', axis='columns')\n",
    "\n",
    "def r2_test_for_all_combinations():\n",
    "    n = desc_without_dependent.columns.size\n",
    "    combs_count = sum((comb(n, k) for k in range(1, n + 1)))\n",
    "    \n",
    "    assert combs_count <= 100, f'Too many possible combinations ({combs_count} > 100) for {n} variables'\n",
    "    \n",
    "    results: list[(float, list[str])] = []\n",
    "    \n",
    "    for i in range(1, desc_without_dependent.columns.size + 1):\n",
    "        for combination in combinations(desc_without_dependent.columns, i):\n",
    "            combination = list(combination)\n",
    "            \n",
    "            r2_test = calculate_coeffs_and_r2_score(\n",
    "                train_data,\n",
    "                test_data,\n",
    "                'Performance Index',\n",
    "                variables_to_keep=combination\n",
    "            )['r2_test']\n",
    "            results.append((r2_test, combination))\n",
    "            \n",
    "    \n",
    "    results.sort(key=lambda result: -result[0])\n",
    "    \n",
    "    for result in results:\n",
    "        print(f'{result[0]:.6f} : {result[1]}')\n",
    "\n",
    "r2_test_for_all_combinations()"
   ],
   "id": "4f49711679931167",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 4.5. Синтетический признак\n",
    "Введём синтетический признак: `Speed Performance` (производительность по скорости), который будет рассчитываться как:\n",
    "$$\n",
    "\\text{Speed Performance} = \\left\\{\\begin{matrix}\n",
    "    \\cfrac{\\text{Sample Question Papers Practiced}}{\\text{Hours Studied}}, & \\text{Hours Studied} > 0, \\\\\n",
    "    \\cfrac{\\text{Sample Question Papers Practiced}}{\\varepsilon}, & \\text{else},\n",
    "\\end{matrix}\\right.\n",
    "$$\n",
    "где $\\varepsilon$ -- маленькое значение.\n",
    "\n",
    "Создаём копию датасета с синтетическим признаком:"
   ],
   "id": "9cb8f3ea470ca13e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "EPSILON = 1e-6",
   "id": "442c020a40462040",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "augm_data = data.copy()\n",
    "augm_data['Speed Performance'] = augm_data['Sample Question Papers Practiced'] / np.where(\n",
    "    augm_data['Hours Studied'] > 0, augm_data['Hours Studied'], EPSILON\n",
    ")\n",
    "augm_data.describe()"
   ],
   "id": "41d1820b8575c56a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Нормируем этот датасет:",
   "id": "787892e1c78c2ca9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "augm_norm_data = (augm_data - augm_data.mean()) / augm_data.std()\n",
    "augm_norm_data"
   ],
   "id": "943f0ad70a0172d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Разделяем его:",
   "id": "60d12b3304a5eff1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "augm_train_data = augm_norm_data[:train_size]\n",
    "augm_test_data = augm_norm_data[train_size:]"
   ],
   "id": "7876a0aa31ecaf1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Строим линейную регрессию и вычисляем $R^2$:",
   "id": "9b87af45e5e6d2ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result4 = calculate_coeffs_and_r2_score(augm_train_data, augm_test_data, 'Performance Index')\n",
    "result4"
   ],
   "id": "afc7e39ef68e3f06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "5. Сравнение результатов моделей\n",
    "Оцениваем, в каком случае $R^2$ получился выше всего:"
   ],
   "id": "68f23e22a5356971"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = [\n",
    "    (result1['r2_test'], 'All variables'),\n",
    "    (result2['r2_test'], 'All variables, excluding \"Sleep Hours\" and \"Extracurricular Activities\"'),\n",
    "    (result3['r2_test'], 'Only \"Sleep Hours\" and \"Extracurricular Activities\"'),\n",
    "    (result4['r2_test'], 'All variables, plus \"Speed Performance\"')\n",
    "]\n",
    "\n",
    "results.sort(key=lambda result: -result[0])\n",
    "for result in results:\n",
    "    print(f'{result[0]:.6f} : {result[1]}')"
   ],
   "id": "d801b2340e4afe22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Добавление синтетического признака немного снизило предсказательную способность модели ($R^2$), что может означать, что этот признак не добавил значимой информации, или даже создал некоторую избыточность в модели.",
   "id": "c4c4622574860142"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
